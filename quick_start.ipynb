{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7227dc6d",
   "metadata": {},
   "source": [
    "# 快速入门\n",
    "\n",
    "本教程中我们将提供一个涵盖`mindcv`的所有基础使用的指南。\n",
    "\n",
    "\n",
    "## 依赖包\n",
    "\n",
    "- mindspore >= 1.8.1\n",
    "- numpy >= 1.17.0\n",
    "- pyyaml >= 5.3\n",
    "- tqdm\n",
    "- openmpi 4.0.3 (for distribute mode) \n",
    "\n",
    "## 安装\n",
    "\n",
    "以下说明假设您已安装所需的依赖包。\n",
    "\n",
    "- pip安装\n",
    "\n",
    "```shell\n",
    "pip install https://github.com/mindlab-ai/mindcv/releases/download/v0.0.1-alpha/mindcv-0.0.1a0-py3-none-any.whl\n",
    "```\n",
    "\n",
    "- 源码安装\n",
    "\n",
    "```shell\n",
    "# 克隆mindcv仓.\n",
    "git clone https://github.com/mindlab-ai/mindcv.git\n",
    "cd mindcv\n",
    "\n",
    "# 安装\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "## 微调DenseNet模型\n",
    "\n",
    "本案例将贯穿Mindcv分类套件的基本流程，以DenseNet网络模型(加载ImageNet数据集的参数)为例子，实现对Cifar10数据集的参数微调。\n",
    "\n",
    "### 环境准备\n",
    "\n",
    "使用`mindspore.context.set_context()`接口对基本环境进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd523cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "ms.context.set_context(mode=ms.context.GRAPH_MODE, device_target='CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea31f5",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- mode: 表示在GRAPH_MODE(0)或PYNATIVE_MODE(1)模式中的运行。默认值：GRAPH_MODE(0)。\n",
    "\n",
    "- device_target: 表示待运行的目标设备，支持’Ascend’、’GPU’和’CPU’。如果未设置此参数，则使用MindSpore包对应的后端设备。\n",
    "\n",
    "## 数据准备\n",
    "\n",
    "使用`mindcv.data.create_dataset`接口下载和解压Cifar10数据集，将数据集转换为MindRecord格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed04ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170052608B [01:08, 2469764.34B/s]                                                                                      \n"
     ]
    }
   ],
   "source": [
    "from mindcv.data import create_dataset, create_transforms, create_loader\n",
    "\n",
    "# 创建数据集。\n",
    "cifar10_dir = './' # 你的数据存放路径\n",
    "num_classes = 10 # 分类的类别数\n",
    "num_workers = 8 # 读取数据的工作线程数 \n",
    "\n",
    "dataset_train = create_dataset(name='cifar10', root=cifar10_dir, split='train', shuffle=True, num_parallel_workers=num_workers, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c675ec",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- name: 数据集名称\n",
    "\n",
    "- dataset_dir: 包含数据集文件的根目录路径。\n",
    "\n",
    "- split: 读取数据集的训练集（\"train\"）或验证集（\"val\"）。默认值：\"train\"。\n",
    "\n",
    "- shuffle: 是否混洗数据集。默认值：None。\n",
    "\n",
    "- num_parallel_workers: 指定读取数据的工作线程数。默认值：None。\n",
    "\n",
    "- download: 是否下载数据集。默认值：False。\n",
    "\n",
    "使用`mindcv.data.create_transformer`接口设置需要对数据进行的数据增强操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb09340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建所需的数据增强操作的列表。\n",
    "trans = create_transforms(dataset_name='cifar10', image_resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ec1b8",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- name: 数据集名称\n",
    "\n",
    "- dataset_dir: 包含数据集文件的根目录路径。\n",
    "\n",
    "- split: 读取数据集的训练集（\"train\"）或验证集（\"val\"）。默认值：\"train\"。\n",
    "\n",
    "- shuffle: 是否混洗数据集。默认值：None。\n",
    "\n",
    "- num_parallel_workers: 指定读取数据的工作线程数。默认值：None。\n",
    "\n",
    "- download: 是否下载数据集。默认值：False。\n",
    "\n",
    "使用`mindcv.data.create_loader`接口生成用于相应任务的数据集，执行所需的数据处理（数据增强，设置batch_size等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c00ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n"
     ]
    }
   ],
   "source": [
    "# 执行数据增强操作，生成所需数据集。\n",
    "loader_train = create_loader(dataset=dataset_train,\n",
    "                             batch_size=64,\n",
    "                             is_training=True,\n",
    "                             num_classes=num_classes,\n",
    "                             transform=trans,\n",
    "                             num_parallel_workers=num_workers)\n",
    "\n",
    "steps_per_epoch = loader_train.get_dataset_size()\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d4796",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- dataset: 通过标准数据集接口（mindspore.dataset.Cifar10Dataset，mindspore.dataset.CocoDataset）或者自定义数据集接口（mindspore.dataset.GeneratorDataset）加载过的数据集。\n",
    "\n",
    "- batch_size: 指定每个批处理数据包含的数据条目。\n",
    "\n",
    "- is_training: 读取数据集的训练集（True）或验证集（False）。默认值：False。\n",
    "\n",
    "- num_classes: 分类的类别数。默认值：1000。\n",
    "    \n",
    "- transform: 所需的数据增强操作的列表。默认值：None。\n",
    "\n",
    "- num_parallel_workers: 指定读取数据的工作线程数。默认值：None。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7cc5aa",
   "metadata": {},
   "source": [
    "## 模型微调\n",
    "\n",
    "使用`mindcv.models.create_model`接口实例化DenseNet，并加载预训练权重densenet_121_imagenet2012.ckpt（ImageNet数据集训练得到）。\n",
    "\n",
    "> 由于Cifar10和ImageNet数据集所需分类的类别数量不同，分类器参数无法共享，所以会出现分类器参数无法加载的告警。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d940e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(5752:20344,MainProcess):2022-09-20-09:36:31.407.643 [mindspore\\train\\serialization.py:709] For 'load_param_into_net', 2 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.\n",
      "[WARNING] ME(5752:20344,MainProcess):2022-09-20-09:36:31.423.268 [mindspore\\train\\serialization.py:714] classifier.weight is not loaded.\n",
      "[WARNING] ME(5752:20344,MainProcess):2022-09-20-09:36:31.423.268 [mindspore\\train\\serialization.py:714] classifier.bias is not loaded.\n"
     ]
    }
   ],
   "source": [
    "from mindcv.models import create_model\n",
    "\n",
    "# 实例化 DenseNet-121 模型并加载预训练权重。\n",
    "network = create_model(model_name='densenet121', num_classes=num_classes, pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afd4c1",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- model_name: 需要加载的模型的规格的名称。\n",
    "\n",
    "- num_classes: 分类的类别数。默认值：1000。\n",
    "\n",
    "- pretrained: 是否加载与训练权重。默认值：False。\n",
    "\n",
    "使用`mindcv.loss.create_loss`接口创建损失函数（cross_entropy loss）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea634e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindcv.loss import create_loss\n",
    "\n",
    "# 设置损失函数\n",
    "loss = create_loss(name='CE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf053b",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- name: 需要加载的模型的规格的名称。\n",
    "\n",
    "使用`mindcv.scheduler.create_scheduler`接口设置学习率策略（warmup_consine_decay）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8198fafd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mindcv.scheduler import create_scheduler\n",
    "\n",
    "# 设置学习率策略\n",
    "lr_scheduler = create_scheduler(steps_per_epoch=steps_per_epoch,\n",
    "                                scheduler='constant',\n",
    "                                lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd1fd6",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- steps_pre_epoch: 完成一轮训练所需要的步数。\n",
    "\n",
    "- scheduler: 学习率策略的名称。\n",
    "\n",
    "- lr: 学习率的最大值。\n",
    "\n",
    "- min_lr: 学习率的最小值。\n",
    "\n",
    "使用`mindcv.optim.create_optimizer`接口创建优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ad244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindcv.optim import create_optimizer\n",
    "\n",
    "# 设置优化器\n",
    "opt = create_optimizer(network.trainable_params(), opt='adam', lr=lr_scheduler) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40616e55",
   "metadata": {},
   "source": [
    "参数说明:\n",
    "\n",
    "- params: 需要优化的参数的列表。\n",
    "\n",
    "- scheduler: 学习了策略的名称。\n",
    "\n",
    "- lr: 学习率的最大值。\n",
    "\n",
    "- min_lr: 学习率的最小值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df59029",
   "metadata": {},
   "source": [
    "使用[mindspore.Model](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.Model.html)接口根据用户传入的参数封装可训练的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd54125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Model\n",
    "\n",
    "# 封装可训练或推理的实例\n",
    "model = Model(network, loss_fn=loss, optimizer=opt, metrics={'acc'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85b9af",
   "metadata": {},
   "source": [
    "使用[`mindspore.LossMonitor`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.LossMonitor.html)接口训练场景下，监控训练的loss；\n",
    "\n",
    "使用[`mindspore.TimeMonitor`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.TimeMonitor.html)接口监控训练或推理的时间；\n",
    "\n",
    "使用[`mindspore.CheckpointConfig`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.CheckpointConfig.html)接口保存checkpoint时的配置策略；\n",
    "\n",
    "使用[`mindspore.ModelCheckpoint`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.ModelCheckpoint.html)接口在训练过程中调用该方法可以保存网络参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1e250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import LossMonitor, TimeMonitor, CheckpointConfig, ModelCheckpoint\n",
    "\n",
    "# 设置监控训练的loss和接口训练时间的回调函数\n",
    "loss_cb, time_cb = LossMonitor(per_print_times=10), TimeMonitor(data_size=10)\n",
    "\n",
    "# 设置在训练过程中保存网络参数的回调函数\n",
    "ckpt_save_dir = './ckpt' # 参数文件保存路径\n",
    "ckpt_config = CheckpointConfig(save_checkpoint_steps=steps_per_epoch)\n",
    "ckpt_cb = ModelCheckpoint(prefix='densenet121-cifar10',\n",
    "                          directory=ckpt_save_dir,\n",
    "                          config=ckpt_config)\n",
    "\n",
    "# 将所有回调函数添加到一个列表中\n",
    "callbacks = [loss_cb, time_cb, ckpt_cb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55edc5d",
   "metadata": {},
   "source": [
    "使用[`mindspore.Model.train`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.Model.html#mindspore.Model.train)接口进行模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(10, loader_train, callbacks=callbacks, dataset_sink_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea15229",
   "metadata": {},
   "source": [
    "```text\n",
    "epoch: 1 step: 10, loss is 5.531197547912598\n",
    "epoch: 1 step: 20, loss is 3.432859182357788\n",
    "epoch: 1 step: 30, loss is 3.01476788520813\n",
    "epoch: 1 step: 40, loss is 2.79731822013855\n",
    "epoch: 1 step: 50, loss is 2.3083176612854004\n",
    "epoch: 1 step: 60, loss is 2.6279938220977783\n",
    "epoch: 1 step: 70, loss is 2.6907918453216553\n",
    "epoch: 1 step: 80, loss is 2.5941648483276367\n",
    "epoch: 1 step: 90, loss is 2.298828125\n",
    "epoch: 1 step: 100, loss is 2.2227189540863037\n",
    "...\n",
    "```\n",
    "\n",
    "## 模型验证\n",
    "\n",
    "加载验证数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3155e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载验证数据集\n",
    "dataset_val = create_dataset(name='cifar10', root=\"./cifar-10-batches-bin\", split='test', shuffle=True, num_parallel_workers=num_workers, download=False)\n",
    "\n",
    "# 执行数据增强操作，生成所需数据集。\n",
    "loader_val = create_loader(dataset=dataset_val,\n",
    "                           batch_size=64,\n",
    "                           is_training=False,\n",
    "                           num_classes=num_classes,\n",
    "                           transform=trans,\n",
    "                           num_parallel_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761be1c",
   "metadata": {},
   "source": [
    "加载微调后的参数文件（densenet-cifar10-10_782.ckpt）到模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f698e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import load_param_into_net, load_checkpoint\n",
    "\n",
    "# 实例化 DenseNet-121 模型\n",
    "network_eval = create_model(model_name='densenet121', num_classes=num_classes, pretrained=False)\n",
    "\n",
    "# 加载参数到 DenseNet-121 模型中\n",
    "print(load_param_into_net(network_eval, load_checkpoint('./ckpt/densenet-cifar10-10_782.ckpt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a874f42",
   "metadata": {},
   "source": [
    "根据用户传入的参数封装可推理的实例，加载验证数据集，验证微调的 DenseNet121模型精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4e013bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.9565}\n"
     ]
    }
   ],
   "source": [
    "# 根据用户传入的参数封装可推理的实例\n",
    "model_val =  Model(network_eval, loss_fn=loss, optimizer=None, metrics={'acc'})\n",
    "\n",
    "# 验证微调后的DenseNet-121的精度\n",
    "acc = model_val.eval(loader_val, dataset_sink_mode=False)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530aab32",
   "metadata": {},
   "source": [
    "## 模型训练和验证（YAML文件）\n",
    "\n",
    "我们还可以直接使用设置好模型参数的yaml文件来对模型进行训练和验证。\n",
    "\n",
    "> [使用yaml文件的教程](./learn_about_config.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -c config/densenet/densenet121_gpu.yaml \\\n",
    "                 --data_dir ./cifar-10-batches-bin \\\n",
    "                 --dataset cifar10 \\ \n",
    "                 --dataset_download True \\\n",
    "                 --pretrained True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0961d",
   "metadata": {},
   "source": [
    "```text\n",
    "epoch: 1 step: 20018, loss is 5.91997766494751\n",
    "Train epoch time: 2884704.669 ms, per step time: 144.106 ms\n",
    "epoch: 2 step: 20018, loss is 5.552463531494141\n",
    "Train epoch time: 2329894.186 ms, per step time: 116.390 ms\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python validate.py -c config/densenet/densenet121_gpu.yaml \\\n",
    "                    --data_dir ./cifar-10-batches-bin \\\n",
    "                    --dataset cifar10 \\\n",
    "                    --ckpt_path ./ckpt/densenet-cifar10-10_782.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c311583",
   "metadata": {},
   "source": [
    "```text\n",
    "{'Top_1_Accuracy': 0.9565, 'Top_5_Accuracy': 0.9903}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
